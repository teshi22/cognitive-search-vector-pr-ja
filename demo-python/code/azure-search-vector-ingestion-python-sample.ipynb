{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search - Code Sample for chunking documents and generating vector embeddings via indexer composition\n",
    "\n",
    "This code demonstrates a pattern of composing multiple indexers to ingest content from blob storage documents, chunk them, generate embeddings and store them as their own documents in a search index. The code sample here will demonstrate storing the chunked document fragments in their own index, but users can choose to co-locate them in the same index if needed. The following image describes this composition pattern\n",
    "\n",
    "![Indexer chunk composition](../data/images/indexer-composition.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "To run the code, install the following packages. Please use the latest pre-release version `pip install azure-search-documents --pre`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: azure-search-documents==11.4.0a20230509004 in /home/taishi/.local/lib/python3.10/site-packages (11.4.0a20230509004)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in /home/taishi/.local/lib/python3.10/site-packages (from azure-search-documents==11.4.0a20230509004) (1.26.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in /home/taishi/.local/lib/python3.10/site-packages (from azure-search-documents==11.4.0a20230509004) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /home/taishi/.local/lib/python3.10/site-packages (from azure-search-documents==11.4.0a20230509004) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/taishi/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (2.28.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /home/taishi/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/taishi/.local/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /home/taishi/.local/lib/python3.10/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/taishi/.local/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /home/taishi/.local/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai) (1.4.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai[datalib] in /home/taishi/.local/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /home/taishi/.local/lib/python3.10/site-packages (from openai[datalib]) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/taishi/.local/lib/python3.10/site-packages (from openai[datalib]) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /home/taishi/.local/lib/python3.10/site-packages (from openai[datalib]) (3.8.4)\n",
      "Requirement already satisfied: numpy in /home/taishi/.local/lib/python3.10/site-packages (from openai[datalib]) (1.25.0)\n",
      "Requirement already satisfied: pandas>=1.2.3 in /home/taishi/.local/lib/python3.10/site-packages (from openai[datalib]) (1.5.2)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /home/taishi/.local/lib/python3.10/site-packages (from openai[datalib]) (2.0.2.230605)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in /home/taishi/.local/lib/python3.10/site-packages (from openai[datalib]) (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/taishi/.local/lib/python3.10/site-packages (from openpyxl>=3.0.7->openai[datalib]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/taishi/.local/lib/python3.10/site-packages (from pandas>=1.2.3->openai[datalib]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/taishi/.local/lib/python3.10/site-packages (from pandas>=1.2.3->openai[datalib]) (2022.7)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in /home/taishi/.local/lib/python3.10/site-packages (from pandas-stubs>=1.1.0.11->openai[datalib]) (2023.3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.20->openai[datalib]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.20->openai[datalib]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.20->openai[datalib]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.20->openai[datalib]) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai[datalib]) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai[datalib]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai[datalib]) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai[datalib]) (1.4.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai[datalib]) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/taishi/.local/lib/python3.10/site-packages (from aiohttp->openai[datalib]) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai[datalib]) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /home/taishi/.local/lib/python3.10/site-packages (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: azure-storage-blob in /home/taishi/.local/lib/python3.10/site-packages (12.14.1)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.2 in /home/taishi/.local/lib/python3.10/site-packages (from azure-storage-blob) (1.26.1)\n",
      "Requirement already satisfied: msrest>=0.7.1 in /home/taishi/.local/lib/python3.10/site-packages (from azure-storage-blob) (0.7.1)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /home/taishi/.local/lib/python3.10/site-packages (from azure-storage-blob) (38.0.4)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/taishi/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.2->azure-storage-blob) (2.28.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core<2.0.0,>=1.24.2->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /home/taishi/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.2->azure-storage-blob) (4.4.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/taishi/.local/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/taishi/.local/lib/python3.10/site-packages (from msrest>=0.7.1->azure-storage-blob) (2022.12.7)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /home/taishi/.local/lib/python3.10/site-packages (from msrest>=0.7.1->azure-storage-blob) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /home/taishi/.local/lib/python3.10/site-packages (from msrest>=0.7.1->azure-storage-blob) (1.3.1)\n",
      "Requirement already satisfied: pycparser in /home/taishi/.local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.2->azure-storage-blob) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.2->azure-storage-blob) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/taishi/.local/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.2->azure-storage-blob) (1.26.13)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.7.1->azure-storage-blob) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install azure-search-documents==11.4.0a20230509004 # バージョン固定 [teshi22]\n",
    "! pip install openai\n",
    "! pip install openai[datalib]\n",
    "! pip install python-dotenv\n",
    "! pip install azure-storage-blob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the custom web API skill for chunking + embedding\n",
    "\n",
    "This sample code also relies on a custom web api skill to be deployed to Azure functions. The custom web api skill performs chunking of content and then generates vector embeddings from the content utilizing Azure Open AI service. The code for the custom web api skill is available as an [Azure Cognitive Search power skill](https://github.com/Azure-Samples/azure-search-power-skills/blob/main/Vector/EmbeddingGenerator/README.md) and can be easily deployed via Visual Studio Code to Azure functions.\n",
    "\n",
    "Please follow those steps first and ensure that the function app is running before proceeding with the rest of the sample."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring storage accounts for deletion detection\n",
    "\n",
    "The storage accounts used for storing both the source documents as well as for storing the knowledge store projections (after the \"chunking + embedding\" step) need to adhere to the following requirements, in order to seamlessly track document deletes:\n",
    "\n",
    "1. They need to be of type \"Standard general-purpose v2\".\n",
    "2. They need to have soft delete enabled. Learn more [here](https://learn.microsoft.com/azure/storage/blobs/soft-delete-blob-enable?tabs=azure-portal)\n",
    "\n",
    "Learn more about deletion detection policies used in Azure Cognitive Search [here](https://learn.microsoft.com/azure/search/search-howto-index-changed-deleted-blobs?tabs=portal#native-blob-soft-delete-preview)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage the index, data source, skillset and indexer for the source document\n",
    "\n",
    "The following code will configure an index to hold the source documents, via an indexer that reads data from an Azure storage container that is able to generate embeddings and write that to a separate storage account (knowledge store)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchField,\n",
    "    SearchableField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndexer,\n",
    "    IndexingParameters,\n",
    "    FieldMapping,\n",
    "    FieldMappingFunction,\n",
    "    InputFieldMappingEntry, \n",
    "    OutputFieldMappingEntry, \n",
    "    SearchIndexerSkillset,\n",
    "    SearchIndexerKnowledgeStore,\n",
    "    SearchIndexerKnowledgeStoreProjection,\n",
    "    SearchIndexerKnowledgeStoreFileProjectionSelector,\n",
    "    IndexingParameters, \n",
    "    WebApiSkill,\n",
    "    SearchIndex,\n",
    "    SemanticSettings,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmConfiguration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  # 追加[teshi22]\n",
    "load_dotenv()  # 追加[teshi22]\n",
    "\n",
    "AZURE_SEARCH_SERVICE_ENDPOINT = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "AZURE_SEARCH_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "AZURE_SEARCH_KNOWLEDGE_STORE_CONNECTION_STRING = os.getenv(\"AZURE_KNOWLEDGE_STORE_STORAGE_CONNECTION_STRING\")\n",
    "\n",
    "def get_index_client() -> SearchIndexClient:\n",
    "    return SearchIndexClient(AZURE_SEARCH_SERVICE_ENDPOINT, AzureKeyCredential(AZURE_SEARCH_KEY))\n",
    "\n",
    "def get_indexer_client() -> SearchIndexerClient:\n",
    "    return SearchIndexerClient(AZURE_SEARCH_SERVICE_ENDPOINT, AzureKeyCredential(AZURE_SEARCH_KEY))\n",
    "\n",
    "def get_index_name(index_prefix):\n",
    "    return f\"{index_prefix}-index\"\n",
    "\n",
    "def get_datasource_name(index_prefix):\n",
    "    return f\"{index_prefix}-datasource\"\n",
    "\n",
    "def get_skillset_name(index_prefix):\n",
    "    return f\"{index_prefix}-skillset\"\n",
    "\n",
    "def get_indexer_name(index_prefix):\n",
    "    return f\"{index_prefix}-indexer\"\n",
    "\n",
    "def get_chunk_index_blob_container_name(index_prefix):\n",
    "    return f\"{index_prefix}ChunkIndex\".replace('-', '').lower()\n",
    "\n",
    "def get_knowledge_store_connection_string():\n",
    "    return AZURE_SEARCH_KNOWLEDGE_STORE_CONNECTION_STRING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define simple utilities to to help configure index, data source, skillset (with knowledge store) and indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name, fields, vector_search, semantic_title_field_name, semantic_content_field_names):\n",
    "    semantic_settings = SemanticSettings(\n",
    "        configurations=[SemanticConfiguration(\n",
    "            name='default',\n",
    "            prioritized_fields=PrioritizedFields(\n",
    "                title_field=SemanticField(field_name=semantic_title_field_name), prioritized_content_fields=[SemanticField(field_name=field_name) for field_name in semantic_content_field_names]))])\n",
    "    index = SearchIndex(\n",
    "        name=index_name,\n",
    "        fields=fields,\n",
    "        vector_search=vector_search,\n",
    "        semantic_settings=semantic_settings)\n",
    "    index_client = get_index_client()\n",
    "    return index_client.create_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blob_datasource(datasource_name, storage_connection_string, container_name):\n",
    "    # This example utilizes a REST request as the python SDK doesn't support the blob soft delete policy yet\n",
    "    api_version = '2023-07-01-Preview'\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'api-key': f'{AZURE_SEARCH_KEY}'\n",
    "    }\n",
    "    data_source = {\n",
    "        \"name\": datasource_name,\n",
    "        \"type\": \"azureblob\",\n",
    "        \"credentials\": {\"connectionString\": storage_connection_string},\n",
    "        \"container\": {\"name\": container_name},\n",
    "        \"dataDeletionDetectionPolicy\": {\"@odata.type\": \"#Microsoft.Azure.Search.NativeBlobSoftDeleteDeletionDetectionPolicy\"}\n",
    "    }\n",
    "\n",
    "    url = '{}/datasources/{}?api-version={}'.format(AZURE_SEARCH_SERVICE_ENDPOINT, datasource_name, api_version)\n",
    "    response = requests.put(url, json=data_source, headers=headers)\n",
    "\n",
    "    ds_client = get_indexer_client()\n",
    "    return ds_client.get_data_source_connection(datasource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_indexer_completion(indexer_name):\n",
    "    indexer_client = get_indexer_client()\n",
    "    # poll status and wait until indexer is complete\n",
    "    status = f\"Indexer {indexer_name} not started yet\"\n",
    "    while (indexer_client.get_indexer_status(indexer_name).last_result == None) or ((status := indexer_client.get_indexer_status(indexer_name).last_result.status) != \"success\"):\n",
    "        print(f\"Indexing status:{status}\")\n",
    "\n",
    "        # It's possible that the indexer may reach a state of transient failure, especially when generating embeddings\n",
    "        # via Open AI. For the purposes of the demo, we'll just break out of the loop and continue with the rest of the steps.\n",
    "        if (status == \"transientFailure\"):\n",
    "            print(f\"Indexer {indexer_name} failed before fully indexing documents\")\n",
    "            break\n",
    "        time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities to manage the \"source\" document index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentIndexManager():\n",
    "    def _create_document_index(self, index_prefix):\n",
    "        name = get_index_name(index_prefix)\n",
    "        fields = [\n",
    "            SimpleField(name=\"document_id\", type=SearchFieldDataType.String, filterable=True, sortable=True, key=True),\n",
    "            SearchableField(name=\"content\", type=SearchFieldDataType.String, analyzer=\"ja.lucene\"), # \"ja.lucene\"に変更 [teshi22]\n",
    "            SimpleField(name=\"filesize\", type=SearchFieldDataType.Int64),\n",
    "            SimpleField(name=\"filepath\", type=SearchFieldDataType.String)\n",
    "        ]\n",
    "        return create_index(name, fields, vector_search=None, semantic_title_field_name=\"filepath\", semantic_content_field_names=[\"content\"])\n",
    "\n",
    "    def _create_document_datasource(self, index_prefix, storage_connection_string, container_name):\n",
    "        name = get_datasource_name(index_prefix)\n",
    "        return create_blob_datasource(name, storage_connection_string, container_name)\n",
    "\n",
    "    def _create_document_skillset(self, index_prefix, content_field_name=\"content\"):\n",
    "        embedding_skill_endpoint = os.getenv(\"AZURE_SEARCH_EMBEDDING_SKILL_ENDPOINT\")\n",
    "\n",
    "        name = get_skillset_name(index_prefix)\n",
    "        chunk_index_blob_container_name = get_chunk_index_blob_container_name(index_prefix)\n",
    "        content_context = f\"/document/{content_field_name}\"\n",
    "        embedding_skill = WebApiSkill(\n",
    "                            name=\"chunking-embedding-skill\",\n",
    "                            uri=embedding_skill_endpoint,\n",
    "                            timeout=\"PT3M\",\n",
    "                            batch_size=1,\n",
    "                            degree_of_parallelism=1,\n",
    "                            context=content_context,\n",
    "                            inputs=[\n",
    "                                    InputFieldMappingEntry(name=\"document_id\", source=\"/document/document_id\"),\n",
    "                                    InputFieldMappingEntry(name=\"text\", source=content_context),\n",
    "                                    InputFieldMappingEntry(name=\"filepath\", source=\"/document/filepath\"),\n",
    "                                    InputFieldMappingEntry(name=\"fieldname\", source=f\"='{content_field_name}'\")],\n",
    "                            outputs=[OutputFieldMappingEntry(name=\"chunks\", target_name=\"chunks\")])\n",
    "        knowledge_store = SearchIndexerKnowledgeStore(storage_connection_string=get_knowledge_store_connection_string(),\n",
    "                                                    projections=[\n",
    "                                                                SearchIndexerKnowledgeStoreProjection(\n",
    "                                                                    objects=[SearchIndexerKnowledgeStoreFileProjectionSelector(\n",
    "                                                                        storage_container=chunk_index_blob_container_name,\n",
    "                                                                        generated_key_name=\"id\",\n",
    "                                                                        source_context=f\"{content_context}/chunks/*\",\n",
    "                                                                        inputs=[\n",
    "                                                                            InputFieldMappingEntry(name=\"source_document_id\", source=\"/document/document_id\"),\n",
    "                                                                            InputFieldMappingEntry(name=\"source_document_filepath\", source=\"/document/filepath\"),\n",
    "                                                                            InputFieldMappingEntry(name=\"source_field_name\", source=f\"{content_context}/chunks/*/embedding_metadata/fieldname\"),\n",
    "                                                                            InputFieldMappingEntry(name=\"title\", source=f\"{content_context}/chunks/*/title\"),\n",
    "                                                                            InputFieldMappingEntry(name=\"text\", source=f\"{content_context}/chunks/*/content\"),\n",
    "                                                                            InputFieldMappingEntry(name=\"embedding\", source=f\"{content_context}/chunks/*/embedding_metadata/embedding\"),\n",
    "                                                                            InputFieldMappingEntry(name=\"index\", source=f\"{content_context}/chunks/*/embedding_metadata/index\"),\n",
    "                                                                            InputFieldMappingEntry(name=\"offset\", source=f\"{content_context}/chunks/*/embedding_metadata/offset\"),\n",
    "                                                                            InputFieldMappingEntry(name=\"length\", source=f\"{content_context}/chunks/*/embedding_metadata/length\")                                                                            \n",
    "                                                                            ]\n",
    "                                                                            )\n",
    "                                                                    ]),\n",
    "                                                                SearchIndexerKnowledgeStoreProjection(\n",
    "                                                                files=[SearchIndexerKnowledgeStoreFileProjectionSelector(\n",
    "                                                                    storage_container=f\"{chunk_index_blob_container_name}images\",\n",
    "                                                                    generated_key_name=\"imagepath\",\n",
    "                                                                    source=\"/document/normalized_images/*\",\n",
    "                                                                    inputs=[]\n",
    "                                                                        )\n",
    "                                                                ])\n",
    "                                                                ])\n",
    "        skillset = SearchIndexerSkillset(name=name, skills=[embedding_skill], description=name, knowledge_store=knowledge_store)\n",
    "        client = get_indexer_client()\n",
    "        return client.create_skillset(skillset)\n",
    "\n",
    "    def _create_document_indexer(self, index_prefix, data_source_name, index_name, skillset_name, content_field_name=\"content\", generate_page_images=True):\n",
    "        content_context = f\"/document/{content_field_name}\"\n",
    "        name = get_indexer_name(index_prefix)\n",
    "        indexer_config = {\"dataToExtract\": \"contentAndMetadata\", \"imageAction\": \"generateNormalizedImagePerPage\"} if generate_page_images else {\"dataToExtract\": \"contentAndMetadata\"}\n",
    "        parameters = IndexingParameters(max_failed_items = -1, configuration=indexer_config)\n",
    "        indexer = SearchIndexer(\n",
    "            name=name,\n",
    "            data_source_name=data_source_name,\n",
    "            target_index_name=index_name,\n",
    "            skillset_name=skillset_name,\n",
    "            field_mappings=[FieldMapping(source_field_name=\"metadata_storage_path\", target_field_name=\"document_id\", mapping_function=FieldMappingFunction(name=\"base64Encode\", parameters=None)),\n",
    "                            FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"filepath\"),\n",
    "                            FieldMapping(source_field_name=\"metadata_storage_size\", target_field_name=\"filesize\")],\n",
    "            output_field_mappings=[],\n",
    "            parameters=parameters\n",
    "        )\n",
    "        indexer_client = get_indexer_client()\n",
    "        return indexer_client.create_indexer(indexer)\n",
    "\n",
    "    def create_document_index_resources(self, index_prefix, customer_storage_connection_string, customer_container_name) -> dict:\n",
    "        index_name = self._create_document_index(index_prefix).name\n",
    "        data_source_name = self._create_document_datasource(index_prefix, customer_storage_connection_string, customer_container_name).name\n",
    "        skillset_name = self._create_document_skillset(index_prefix).name    \n",
    "        time.sleep(5)\n",
    "        indexer_name = self._create_document_indexer(index_prefix, data_source_name, index_name, skillset_name).name\n",
    "        wait_for_indexer_completion(indexer_name)\n",
    "        return {\"index_name\": index_name, \"data_source_name\": data_source_name, \"skillset_name\": skillset_name, \"indexer_name\": indexer_name}\n",
    "\n",
    "    def delete_document_index_resources(self, index_prefix):\n",
    "        index_client = get_index_client()\n",
    "        indexer_client = get_indexer_client()\n",
    "\n",
    "        index_client.delete_index(index=get_index_name(index_prefix))\n",
    "        indexer_client.delete_indexer(indexer=get_indexer_name(index_prefix))\n",
    "        indexer_client.delete_data_source_connection(data_source_connection=get_datasource_name(index_prefix))\n",
    "        indexer_client.delete_skillset(skillset=get_skillset_name(index_prefix))\n",
    "\n",
    "        # delete the knowledge store tables and blobs\n",
    "        knowledge_store_connection_string  = get_knowledge_store_connection_string()\n",
    "        \n",
    "        # delete the container directly from storage\n",
    "        try:\n",
    "            blob_service = BlobServiceClient.from_connection_string(knowledge_store_connection_string)\n",
    "            blob_service.delete_container(get_chunk_index_blob_container_name(index_prefix))\n",
    "        # handle resource not found error\n",
    "        except ResourceNotFoundError:\n",
    "            pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities to manage the \"chunked\" document index - with vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkIndexManager():\n",
    "\n",
    "    def _create_chunk_index(self, index_prefix):\n",
    "        name = get_index_name(f\"{index_prefix}-chunk\")\n",
    "        vector_search = VectorSearch(\n",
    "            algorithm_configurations=[\n",
    "                VectorSearchAlgorithmConfiguration(\n",
    "                    name=\"my-vector-config\",\n",
    "                    kind=\"hnsw\",\n",
    "                    hnsw_parameters={\n",
    "                        \"m\": 4,\n",
    "                        \"efConstruction\": 400,\n",
    "                        \"efSearch\": 1000,\n",
    "                        \"metric\": \"cosine\"\n",
    "                    }\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        fields = [\n",
    "            SimpleField(name=\"id\", type=SearchFieldDataType.String,  filterable=True, sortable=True, key=True),            \n",
    "            SimpleField(name=\"source_document_id\", type=SearchFieldDataType.String),\n",
    "            SimpleField(name=\"source_document_filepath\", type=SearchFieldDataType.String),\n",
    "            SimpleField(name=\"source_field_name\", type=SearchFieldDataType.String),\n",
    "            SearchableField(name=\"title\", type=SearchFieldDataType.String, analyzer_name=\"ja.lucene\"), # \"ja.lucene\"に変更 [teshi22]\n",
    "            SimpleField(name=\"index\", type=SearchFieldDataType.Int64),\n",
    "            SimpleField(name=\"offset\", type=SearchFieldDataType.Int64),\n",
    "            SimpleField(name=\"length\", type=SearchFieldDataType.Int64),\n",
    "            SimpleField(name=\"hash\", type=SearchFieldDataType.String),\n",
    "            SearchableField(name=\"text\", type=SearchFieldDataType.String, analyzer_name=\"ja.lucene\"), # \"ja.lucene\"に変更 [teshi22]\n",
    "            SearchField(name=\"embedding\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, dimensions=1536, vector_search_configuration=\"my-vector-config\")    \n",
    "        ]\n",
    "        # vector_search_dimensions -> dimensions に変更 [teshi22]\n",
    "        index = create_index(name, fields, vector_search=vector_search, semantic_title_field_name=\"title\", semantic_content_field_names=[\"text\"])\n",
    "        return index\n",
    "    \n",
    "    def _create_chunk_datasource(self, index_prefix, storage_connection_string, container_name):\n",
    "        name = get_datasource_name(f\"{index_prefix}-chunk\")\n",
    "        return create_blob_datasource(name, storage_connection_string, container_name)\n",
    "\n",
    "    def _create_chunk_indexer(self, index_prefix, data_source_name, index_name):\n",
    "        name = get_indexer_name(f\"{index_prefix}-chunk\")\n",
    "        parameters = IndexingParameters(configuration={\"parsing_mode\": \"json\"})\n",
    "        indexer = SearchIndexer(\n",
    "            name=name,\n",
    "            data_source_name=data_source_name,\n",
    "            target_index_name=index_name,\n",
    "            parameters=parameters\n",
    "        )\n",
    "        indexer_client = get_indexer_client()\n",
    "        return indexer_client.create_indexer(indexer)\n",
    "\n",
    "\n",
    "    def create_chunk_index_resources(self, index_prefix) -> dict:\n",
    "        chunk_index_storage_connection_string = get_knowledge_store_connection_string()\n",
    "        chunk_index_blob_container_name = get_chunk_index_blob_container_name(index_prefix)\n",
    "\n",
    "        index_name = self._create_chunk_index(index_prefix).name\n",
    "        data_source_name = self._create_chunk_datasource(index_prefix, chunk_index_storage_connection_string, chunk_index_blob_container_name).name\n",
    "        time.sleep(5)\n",
    "        indexer_name = self._create_chunk_indexer(index_prefix, data_source_name, index_name).name\n",
    "        wait_for_indexer_completion(indexer_name)\n",
    "        return {\"index_name\": index_name, \"data_source_name\": data_source_name, \"indexer_name\": indexer_name}\n",
    "\n",
    "\n",
    "    # delete all the resources\n",
    "    def delete_chunk_index_resources(self, index_prefix):\n",
    "        index_client = get_index_client()\n",
    "        indexer_client = get_indexer_client()\n",
    "\n",
    "        index_client.delete_index(index=f\"{index_prefix}-chunk-index\")\n",
    "        indexer_client.delete_indexer(indexer=f\"{index_prefix}-chunk-indexer\")\n",
    "        indexer_client.delete_data_source_connection(data_source_connection=f\"{index_prefix}-chunk-datasource\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text embedder utility to aid during query time\n",
    "\n",
    "**NOTE**: Make sure to utilize the same Azure OpenAI Embedding Deployment at query time as the one used in the custom web api skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbedder():\n",
    "    openai.api_type = \"azure\"    \n",
    "    openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    openai.api_base = f\"https://{os.getenv('AZURE_OPENAI_SERVICE_NAME')}.openai.azure.com/\"\n",
    "    openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "    AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "\n",
    "    def clean_text(self, text, text_limit=7000):\n",
    "        # Clean up text (e.g. line breaks, )    \n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        text = re.sub(r'[\\n\\r]+', ' ', text).strip()\n",
    "        # Truncate text if necessary (e.g. for, ada-002, 4095 tokens ~ 7000 chracters)    \n",
    "        if len(text) > text_limit:\n",
    "            logging.warning(\"Token limit reached exceeded maximum length, truncating...\")\n",
    "            text = text[:text_limit]\n",
    "        return text\n",
    "\n",
    "    # Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "    def generate_embeddings(self, text, clean_text=True):\n",
    "        if clean_text:\n",
    "            text = self.clean_text(text)\n",
    "        response = openai.Embedding.create(input=text, engine=self.AZURE_OPENAI_EMBEDDING_DEPLOYMENT)\n",
    "        embeddings = response['data'][0]['embedding']\n",
    "        return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wire up the utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indexes(prefix, customer_storage_connection_string, container_name):\n",
    "    index_manager = DocumentIndexManager()\n",
    "    doc_index_resources = index_manager.create_document_index_resources(prefix, customer_storage_connection_string, container_name)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    chunk_index_manager = ChunkIndexManager()\n",
    "    chunk_index_resources = chunk_index_manager.create_chunk_index_resources(prefix)\n",
    "    return {\"doc_index_resources\": doc_index_resources, \"chunk_index_resources\": chunk_index_resources}\n",
    "\n",
    "def delete_indexes(prefix):\n",
    "    index_manager = DocumentIndexManager()\n",
    "    index_manager.delete_document_index_resources(prefix)\n",
    "    chunk_index_manager = ChunkIndexManager()\n",
    "    chunk_index_manager.delete_chunk_index_resources(prefix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "The following code will upload a bunch of sample PDFs to the \"source document\" storage account, in the container specified. And will implement the indexer composition pattern to ingest both the content from the source documents as well as the chunked + embedded content."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the sample data to blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenant ='pythonsample'\n",
    "\n",
    "customer_storage_connection_string = os.getenv(\"DOCUMENT_AZURE_STORAGE_CONNECTION_STRING\")\n",
    "container_name = os.getenv(\"DOCUMENT_AZURE_STORAGE_CONTAINER_NAME\")\n",
    "\n",
    "prefix = f\"{tenant}-{container_name}\"\n",
    "\n",
    "# Delete any existing Azure Cognitive Search resources\n",
    "delete_indexes(prefix)\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(customer_storage_connection_string)\n",
    "container_client = blob_service_client.get_container_client(container=container_name)\n",
    "\n",
    "if not container_client.exists():\n",
    "    container_client.create_container()\n",
    "\n",
    "# Upload sample documents to blob storage\n",
    "for root, dirs, files in os.walk(\"../data/documents/\"):\n",
    "    for file in files:\n",
    "        with open(os.path.join(root, file), \"rb\") as data:\n",
    "            container_client.upload_blob(file, data, overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Azure Cognitive Search resources\n",
    "\n",
    "**NOTE**: The following example creates the source document indexer and the chunk document indexer, but we wait for the first indexer to fully finish its run before creating the second - this is reasonable with very small amounts of data, but wouldn't scale well for larger data. In that scenario it would make more sense to create the indexers in parallel with a schedule and let them run on their own and converge eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtype value #Microsoft.Azure.Search.NativeBlobSoftDeleteDeletionDetectionPolicy has no mapping, use base class DataDeletionDetectionPolicy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing status:Indexer pythonsample-doc-indexer not started yet\n",
      "Indexing status:inProgress\n",
      "Indexing status:inProgress\n",
      "Indexing status:inProgress\n",
      "Indexing status:inProgress\n",
      "Indexing status:inProgress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtype value #Microsoft.Azure.Search.NativeBlobSoftDeleteDeletionDetectionPolicy has no mapping, use base class DataDeletionDetectionPolicy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n",
      "Indexing status:Indexer pythonsample-doc-chunk-indexer not started yet\n"
     ]
    }
   ],
   "source": [
    "# ensure indexes\n",
    "index_resources = create_indexes(prefix, customer_storage_connection_string, container_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the \"chunk\" search index with different kinds of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_index(index_name, query, vector_only=False):\n",
    "    embedder = TextEmbedder()\n",
    "    vector = Vector(value=embedder.generate_embeddings(query), k=3, fields=\"embedding\")\n",
    "    search_client = SearchClient(AZURE_SEARCH_SERVICE_ENDPOINT, index_name, AzureKeyCredential(AZURE_SEARCH_KEY)) \n",
    "    if vector_only:\n",
    "        search_text = None\n",
    "    else:\n",
    "        search_text = query\n",
    "    results = search_client.search(search_text=search_text, vector=vector)\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vector only query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: Azure OpenAI Service とは\n",
      "[アーティクル] • 2023/05/01\n",
      "\n",
      "Azure OpenAI Service では、GPT-3、Codex、Embeddings モデル シリーズなど\n",
      "OpenAI の強⼒な⾔語モデルを REST API として使⽤できます。 さらに、新しい GPT-4\n",
      "および ChatGPT (gpt-35-turbo) モデル シリーズがプレビューで利⽤可能になりまし\n",
      "た。 これらのモデルは、特定のタスクに合わせて簡単に調整できます。たとえば、コ\n",
      "ンテンツの⽣成、まとめ、セマンティック検索、⾃然⾔語からコードへの翻訳などで\n",
      "す。 ユーザーは、REST API、Python SDK、または Azure OpenAI Studio の Web ベース\n",
      "のインターフェイスを介してサービスにアクセスできます。\n",
      "\n",
      "機能 Azure OpenAI\n",
      "\n",
      "使⽤できるモデル 新しい GPT-4 シリーズ (プレビュー)\n",
      "GPT-3 ベース シリーズ\n",
      "新しい ChatGPT (gpt-35-turbo) (プレビュー)\n",
      "Codex シリーズ\n",
      "埋め込みシリーズ\n",
      "詳細については、モデルに関するページを参照してください。\n",
      "\n",
      "微調整 Ada\n",
      "Babbage\n",
      "Curie\n",
      "Cushman*\n",
      "Davinci*\n",
      "* 現在は利⽤できません。 ** ⽶国東部と⻄ヨーロッパでは、現在新\n",
      "規のお客様は微調整を利⽤できません。 ⽶国ベースのトレーニング\n",
      "には、⽶国中南部をご利⽤ください\n",
      "\n",
      "Price こちらで⼊⼿可能\n",
      "\n",
      "仮想ネットワークのサポ\n",
      "ート & プライベート リン\n",
      "クのサポート\n",
      "\n",
      "はい\n",
      "\n",
      "マネージド ID はい、Azure Active Directory 経由\n",
      "\n",
      "UI エクスペリエンス アカウントとリソースの管理には Azure Portal、\n",
      "モデルの探索と微調整には Azure OpenAI Service Studio\n",
      "\n",
      "リージョン別の提供状況 ⽶国東部\n",
      "⽶国中南部\n",
      "⻄ヨーロッパ\n",
      "\n",
      "機能の概要\n",
      "\n",
      "pageimage0.jpg\n",
      "\n",
      "\n",
      "\n",
      "https://learn.microsoft.com/ja-jp/azure/cognitive-services/openai/concepts/models\n",
      "https://azure.microsoft\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: jpg\n",
      "\n",
      "\n",
      "\n",
      "https://learn.microsoft.com/ja-jp/azure/cognitive-services/openai/how-to/create-resource\n",
      "https://learn.microsoft.com/ja-jp/azure/azure-resource-manager/management/overview\n",
      "\n",
      "\n",
      "Azure OpenAI リソースを作成したら、API 呼び出しを開始してテキストを⽣成する前\n",
      "に、モデルをデプロイする必要があります。 このアクションは、Deployment API を使\n",
      "⽤して実⾏できます。 これらの API を使⽤すると、使⽤するモデルを指定できます。\n",
      "\n",
      "Azure OpenAI で使⽤されるモデルでは、⽣成の呼び出しで提供される⾃然⾔語での指\n",
      "⽰と例を使⽤して、要求されているタスクと必要なスキルを識別しています。 この⽅\n",
      "法を使⽤する場合、プロンプトの最初の部分には、⾃然⾔語の指⽰や、必要な特定の\n",
      "タスクの例が含まれます。 次に、最も可能性の⾼い次のテキスト部分を予測すること\n",
      "で、モデルによってタスクが完了します。 この⼿法は、\"コンテキスト内\" 学習と呼ば\n",
      "れます。 これらのモデルは、この⼿順では再トレーニングされませんが、代わりにプ\n",
      "ロンプトに含めるコンテキストに基づいて予測を⾏います。\n",
      "\n",
      "コンテキスト内学習には、主に 3 つのアプローチがあります。少数ショット、ワンシ\n",
      "ョット、ゼロショットです。 これらの⽅法は、モデルに与えられるタスク固有のデー\n",
      "タの量によって異なります。\n",
      "\n",
      "少数ショット: この場合、ユーザーは、期待される応答形式と内容を⽰すいくつかの例\n",
      "を通話プロンプトに含めます。 次の例は、複数の例を提供する数個のプロンプトを⽰\n",
      "しています (最後の答えはモデルによって⽣成されます)。\n",
      "\n",
      "コンテキスト内学習\n",
      "\n",
      "    Convert the questions to a command:\n",
      "    Q: Ask Constance if we need some bread.\n",
      "    A: send-msg `find constance` Do we need some bread?\n",
      "    Q: Send a message to Greg to figure out if things are ready for \n",
      "Wednesday.\n",
      "    A: send-msg `find greg` Is everything ready for Wednesday?\n",
      "    Q: Ask Ilya if we're still having our meeting this evening.\n",
      "    A: send-msg `find ilya` Are we still having a meeting this evening?\n",
      "    Q: Contact the ski store and figure out if I can get my skis fixed \n",
      "before I leave on Thursday\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: com/pricing/details/cognitive-services/openai-service/\n",
      "\n",
      "\n",
      "機能 Azure OpenAI\n",
      "\n",
      "コンテンツのフィルター\n",
      "処理\n",
      "\n",
      "プロンプトと⼊⼒候補は、⾃動システムを使ってコンテンツ ポリシ\n",
      "ーに対して評価されます。 重⼤度の⾼いコンテンツはフィルターで\n",
      "除外されます。\n",
      "\n",
      "Microsoft は、⼈を第⼀に考える原則に基づいて、AI の発展に取り組んでいます。\n",
      "Azure OpenAI で使⽤できる⽣成モデルには、かなりの潜在的利益がありますが、慎重\n",
      "な設計と熟考した軽減策がない場合、そのようなモデルによって、正しくない、また\n",
      "は有害なコンテンツが⽣成される可能性があります。 Microsoft は、悪⽤や意図しない\n",
      "損害から保護するために多⼤な投資を⾏っています。たとえば、明確に定義したユー\n",
      "ス ケースを⽰すことを申請者の要件とする、責任ある AI 使⽤に関する Microsoft の原\n",
      "則 を取り⼊れる、顧客をサポートするコンテンツ フィルターを構築する、オンボー\n",
      "ドされた顧客に対して責任ある AI 実装のガイダンスを提供するなどです。\n",
      "\n",
      "Azure OpenAI にアクセスするにはどうすればよいですか\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n"
     ]
    }
   ],
   "source": [
    "chunk_index_name = index_resources[\"chunk_index_resources\"][\"index_name\"]\n",
    "results = query_vector_index(chunk_index_name, \"OpenAIで使えるモデルを教えて？\", vector_only=True)\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Content: {result['text']}\")  \n",
    "    print(f\"Source Document: {result['source_document_filepath']}\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hybrid query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: jpg\n",
      "\n",
      "\n",
      "\n",
      "https://learn.microsoft.com/ja-jp/azure/cognitive-services/openai/how-to/create-resource\n",
      "https://learn.microsoft.com/ja-jp/azure/azure-resource-manager/management/overview\n",
      "\n",
      "\n",
      "Azure OpenAI リソースを作成したら、API 呼び出しを開始してテキストを⽣成する前\n",
      "に、モデルをデプロイする必要があります。 このアクションは、Deployment API を使\n",
      "⽤して実⾏できます。 これらの API を使⽤すると、使⽤するモデルを指定できます。\n",
      "\n",
      "Azure OpenAI で使⽤されるモデルでは、⽣成の呼び出しで提供される⾃然⾔語での指\n",
      "⽰と例を使⽤して、要求されているタスクと必要なスキルを識別しています。 この⽅\n",
      "法を使⽤する場合、プロンプトの最初の部分には、⾃然⾔語の指⽰や、必要な特定の\n",
      "タスクの例が含まれます。 次に、最も可能性の⾼い次のテキスト部分を予測すること\n",
      "で、モデルによってタスクが完了します。 この⼿法は、\"コンテキスト内\" 学習と呼ば\n",
      "れます。 これらのモデルは、この⼿順では再トレーニングされませんが、代わりにプ\n",
      "ロンプトに含めるコンテキストに基づいて予測を⾏います。\n",
      "\n",
      "コンテキスト内学習には、主に 3 つのアプローチがあります。少数ショット、ワンシ\n",
      "ョット、ゼロショットです。 これらの⽅法は、モデルに与えられるタスク固有のデー\n",
      "タの量によって異なります。\n",
      "\n",
      "少数ショット: この場合、ユーザーは、期待される応答形式と内容を⽰すいくつかの例\n",
      "を通話プロンプトに含めます。 次の例は、複数の例を提供する数個のプロンプトを⽰\n",
      "しています (最後の答えはモデルによって⽣成されます)。\n",
      "\n",
      "コンテキスト内学習\n",
      "\n",
      "    Convert the questions to a command:\n",
      "    Q: Ask Constance if we need some bread.\n",
      "    A: send-msg `find constance` Do we need some bread?\n",
      "    Q: Send a message to Greg to figure out if things are ready for \n",
      "Wednesday.\n",
      "    A: send-msg `find greg` Is everything ready for Wednesday?\n",
      "    Q: Ask Ilya if we're still having our meeting this evening.\n",
      "    A: send-msg `find ilya` Are we still having a meeting this evening?\n",
      "    Q: Contact the ski store and figure out if I can get my skis fixed \n",
      "before I leave on Thursday\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: Azure OpenAI Service とは\n",
      "[アーティクル] • 2023/05/01\n",
      "\n",
      "Azure OpenAI Service では、GPT-3、Codex、Embeddings モデル シリーズなど\n",
      "OpenAI の強⼒な⾔語モデルを REST API として使⽤できます。 さらに、新しい GPT-4\n",
      "および ChatGPT (gpt-35-turbo) モデル シリーズがプレビューで利⽤可能になりまし\n",
      "た。 これらのモデルは、特定のタスクに合わせて簡単に調整できます。たとえば、コ\n",
      "ンテンツの⽣成、まとめ、セマンティック検索、⾃然⾔語からコードへの翻訳などで\n",
      "す。 ユーザーは、REST API、Python SDK、または Azure OpenAI Studio の Web ベース\n",
      "のインターフェイスを介してサービスにアクセスできます。\n",
      "\n",
      "機能 Azure OpenAI\n",
      "\n",
      "使⽤できるモデル 新しい GPT-4 シリーズ (プレビュー)\n",
      "GPT-3 ベース シリーズ\n",
      "新しい ChatGPT (gpt-35-turbo) (プレビュー)\n",
      "Codex シリーズ\n",
      "埋め込みシリーズ\n",
      "詳細については、モデルに関するページを参照してください。\n",
      "\n",
      "微調整 Ada\n",
      "Babbage\n",
      "Curie\n",
      "Cushman*\n",
      "Davinci*\n",
      "* 現在は利⽤できません。 ** ⽶国東部と⻄ヨーロッパでは、現在新\n",
      "規のお客様は微調整を利⽤できません。 ⽶国ベースのトレーニング\n",
      "には、⽶国中南部をご利⽤ください\n",
      "\n",
      "Price こちらで⼊⼿可能\n",
      "\n",
      "仮想ネットワークのサポ\n",
      "ート & プライベート リン\n",
      "クのサポート\n",
      "\n",
      "はい\n",
      "\n",
      "マネージド ID はい、Azure Active Directory 経由\n",
      "\n",
      "UI エクスペリエンス アカウントとリソースの管理には Azure Portal、\n",
      "モデルの探索と微調整には Azure OpenAI Service Studio\n",
      "\n",
      "リージョン別の提供状況 ⽶国東部\n",
      "⽶国中南部\n",
      "⻄ヨーロッパ\n",
      "\n",
      "機能の概要\n",
      "\n",
      "pageimage0.jpg\n",
      "\n",
      "\n",
      "\n",
      "https://learn.microsoft.com/ja-jp/azure/cognitive-services/openai/concepts/models\n",
      "https://azure.microsoft\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: com/pricing/details/cognitive-services/openai-service/\n",
      "\n",
      "\n",
      "機能 Azure OpenAI\n",
      "\n",
      "コンテンツのフィルター\n",
      "処理\n",
      "\n",
      "プロンプトと⼊⼒候補は、⾃動システムを使ってコンテンツ ポリシ\n",
      "ーに対して評価されます。 重⼤度の⾼いコンテンツはフィルターで\n",
      "除外されます。\n",
      "\n",
      "Microsoft は、⼈を第⼀に考える原則に基づいて、AI の発展に取り組んでいます。\n",
      "Azure OpenAI で使⽤できる⽣成モデルには、かなりの潜在的利益がありますが、慎重\n",
      "な設計と熟考した軽減策がない場合、そのようなモデルによって、正しくない、また\n",
      "は有害なコンテンツが⽣成される可能性があります。 Microsoft は、悪⽤や意図しない\n",
      "損害から保護するために多⼤な投資を⾏っています。たとえば、明確に定義したユー\n",
      "ス ケースを⽰すことを申請者の要件とする、責任ある AI 使⽤に関する Microsoft の原\n",
      "則 を取り⼊れる、顧客をサポートするコンテンツ フィルターを構築する、オンボー\n",
      "ドされた顧客に対して責任ある AI 実装のガイダンスを提供するなどです。\n",
      "\n",
      "Azure OpenAI にアクセスするにはどうすればよいですか\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: A: send-msg `find nicolas` Thank you for lunch!\n",
      "    Q: Tell Constance that I won't be home before 19:30 tonight — unmovable \n",
      "meeting.\n",
      "    A: send-msg `find constance` I won't be home before 19:30 tonight. I \n",
      "have a meeting I can't move.\n",
      "    Q: Tell John that I need to book an appointment at 10:30.\n",
      "    A: \n",
      "\n",
      "pageimage3.jpg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "通常、1 つのプロンプトの最⼤⼊⼒⻑に収まる数に応じて、例の数は 0 から 100 の範\n",
      "囲です。 最⼤⼊⼒⻑は、使⽤する特定のモデルによって異なる場合があります。 少数\n",
      "ショット学習を使⽤すると、正確な予測に必要なタスク固有のデータの量を⼤幅に削\n",
      "減できます。 このアプローチは、通常、微調整されたモデルよりもパフォーマンスは\n",
      "正確ではありません。\n",
      "\n",
      "ワンショット: この場合は、1 つの例のみが提供されることを除き、少数ショットの⽅\n",
      "法と同じです。\n",
      "\n",
      "ゼロショット: この場合、モデルに例は提供されず、タスク要求のみが提供されます。\n",
      "\n",
      "このサービスでは、ユーザーはいくつかのモデルにアクセスできます。 各モデルに\n",
      "は、異なる機能と価格ポイントが⽤意されています。\n",
      "\n",
      "GPT-4 モデルは、利⽤可能な最新のモデルです。 これらのモデルは現在プレビュー段\n",
      "階です。 既存の Azure OpenAI のお客様は、このフォームに⼊⼒してアクセスを申請\n",
      "できます。\n",
      "\n",
      "GPT-3 ベース モデルは、Davinci、Curie、Babbage、Ada と呼ばれます (機能では降\n",
      "順、速度では昇順)。\n",
      "\n",
      "Codex シリーズのモデルは GPT-3 の後継であり、⾃然⾔語とコードの両⽅でトレーニ\n",
      "ングされ、⾃然⾔語からコードへのユース ケースに役⽴ちます。 各モデルの詳細につ\n",
      "いては、モデルの概念に関するページを参照してください。\n",
      "\n",
      "Azure OpenAI をサポートする基となるモデルに関する記事を確認します。\n",
      "\n",
      "モデル\n",
      "\n",
      "次の⼿順\n",
      "\n",
      "pageimage4.jpg\n",
      "\n",
      "\n",
      "\n",
      "https://aka.ms/oai/get-gpt4\n",
      "https://learn.microsoft.com/ja-jp/azure/cognitive-services/openai/concepts/models\n",
      "https://learn.microsoft\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: ⾼い需要、今後の製品の機能強化、Microsoft の責任ある AI へのコミットメント を\n",
      "考慮し、現在、アクセスは制限されています。 現在のところ、Microsoft と既存のパー\n",
      "トナーシップ関係があるお客様、リスクの低いユース ケース、軽減策の取り⼊れに取\n",
      "り組んでいるお客様を対象としています。\n",
      "\n",
      "より具体的な情報は、申請フォームに記載されています。 Azure OpenAI に対するアク\n",
      "セスを拡⼤できるよう、責任を持って取り組んでいますので、しばらくお待ちくださ\n",
      "い。\n",
      "\n",
      "アクセスはこちらからお申し込みください。\n",
      "\n",
      "[今すぐ適⽤する]\n",
      "\n",
      "Azure OpenAI Service では、OpenAI GPT-4、GPT-3、Codex、DALL-E モデルを使⽤し\n",
      "た⾼度な⾔語 AI を顧客に提供し、Azure のセキュリティとエンタープライズの約束を\n",
      "実現します。 Azure OpenAI は OpenAI と共に API を共同開発し、互換性を確保し、⼀\n",
      "⽅から他⽅へのスムーズな移⾏を保証します。\n",
      "\n",
      "責任ある AI\n",
      "\n",
      "Azure OpenAI にアクセスするにはどうすれば\n",
      "よいですか?\n",
      "\n",
      "Azure OpenAI と OpenAI の⽐較\n",
      "\n",
      "pageimage1\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: jpg\n",
      "\n",
      "\n",
      "\n",
      "https://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\n",
      "https://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\n",
      "https://aka.ms/oaiapply\n",
      "\n",
      "\n",
      "Azure OpenAI を使⽤すると、顧客は OpenAI と同じモデルを実⾏しながら、Microsoft\n",
      "Azure のセキュリティ機能を使⽤できます。 Azure OpenAI では、プライベート ネット\n",
      "ワーク、リージョンの可⽤性、責任ある AI コンテンツのフィルター処理が提供されま\n",
      "す。\n",
      "\n",
      "⼊⼒候補エンドポイントは、API サービスのコア コンポーネントです。 この API は、\n",
      "モデルのテキストイン、テキストアウト インターフェイスへのアクセスを提供しま\n",
      "す。 ユーザーは、英語のテキスト コマンドを含む⼊⼒プロンプトを⼊⼒するだけで、\n",
      "モデルによってテキスト⼊⼒候補が⽣成されます。\n",
      "\n",
      "単純なプロンプトと⼊⼒候補の例を次に⽰します。\n",
      "\n",
      "プロンプト: \"\"\" count to 5 in a for loop \"\"\"\n",
      "\n",
      "⼊⼒候補: for i in range(1, 6): print(i)\n",
      "\n",
      "Azure OpenAI では、テキストをトークンに分割して処理します。 トークンには、単語\n",
      "または⽂字のチャンクのみを指定できます。 たとえば、\"hamburger\" という単語はト\n",
      "ークン \"ham\"、\"bur\"、\"ger\" に分割されますが、\"pear\" のような短くて⼀般的な単語\n",
      "は 1 つのトークンです。 多くのトークンは、\"hello\" や \"bye\" などの空⽩で始まりま\n",
      "す。\n",
      "\n",
      "所与の要求で処理されるトークンの合計数は、⼊⼒、出⼒、および要求パラメーター\n",
      "の⻑さによって異なります。 処理されるトークンの量は、モデルの応答待機時間とス\n",
      "ループットにも影響します。\n",
      "\n",
      "Azure OpenAI は、Azure の新しい製品オファリングです。 Azure OpenAI は、他の\n",
      "Azure 製品と同じように、Azure サブスクリプションにこのサービス⽤のリソースまた\n",
      "はインスタンスを作成して使⽤を開始できます。 Azure のリソース管理設計について\n",
      "詳しくご覧いただけます。\n",
      "\n",
      "主要な概念\n",
      "\n",
      "プロンプトと⼊⼒候補\n",
      "\n",
      "トークン\n",
      "\n",
      "リソース\n",
      "\n",
      "デプロイメント\n",
      "\n",
      "pageimage2.jpg\n",
      "\n",
      "\n",
      "\n",
      "https://learn.microsoft\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: jpg\n",
      "\n",
      "\n",
      "\n",
      "https://aka.ms/oai/get-gpt4\n",
      "https://learn.microsoft.com/ja-jp/azure/cognitive-services/openai/concepts/models\n",
      "https://learn.microsoft.com/ja-jp/azure/cognitive-services/openai/concepts/models\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Title: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n",
      "Content: A: send-msg `find greg` Is everything ready for Wednesday?\n",
      "    Q: Ask Ilya if we're still having our meeting this evening.\n",
      "    A: send-msg `find ilya` Are we still having a meeting this evening?\n",
      "    Q: Contact the ski store and figure out if I can get my skis fixed \n",
      "before I leave on Thursday.\n",
      "    A: send-msg `find ski store` Would it be possible to get my skis fixed \n",
      "before I leave on Thursday?\n",
      "    Q: Thank Nicolas for lunch.\n",
      "    A: send-msg `find nicolas` Thank you for lunch!\n",
      "    Q: Tell Constance that I won't be home before 19:30 tonight — unmovable \n",
      "meeting.\n",
      "    A: send-msg `find constance` I won't be home before 19:30 tonight. I \n",
      "have a meeting I can't move.\n",
      "    Q: Tell John that I need to book an appointment at 10:30.\n",
      "    A: \n",
      "\n",
      "pageimage3\n",
      "Source Document: Azure OpenAI Service とは - Azure Cognitive Services _ Microsoft Learn.pdf\n"
     ]
    }
   ],
   "source": [
    "chunk_index_name = index_resources[\"chunk_index_resources\"][\"index_name\"]\n",
    "results = query_vector_index(chunk_index_name, \"OpenAIで使えるモデルを教えて？\")\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Content: {result['text']}\")  \n",
    "    print(f\"Source Document: {result['source_document_filepath']}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiofiles==23.1.0\n",
      "aiohttp==3.8.4\n",
      "aioice==0.7.6\n",
      "aiortc==1.4.0\n",
      "aiosignal==1.3.1\n",
      "altair==4.2.2\n",
      "anyio==3.6.2\n",
      "argilla==1.6.0\n",
      "argon2-cffi==21.3.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.2.3\n",
      "artifacts-keyring==0.3.3\n",
      "asttokens==2.2.1\n",
      "async-timeout==4.0.2\n",
      "attrs==22.2.0\n",
      "av==10.0.0\n",
      "azure-cognitiveservices-speech==1.25.0\n",
      "azure-common==1.1.28\n",
      "azure-core==1.26.1\n",
      "azure-cosmos==4.3.0\n",
      "azure-functions==1.15.0\n",
      "azure-identity==1.13.0b4\n",
      "azure-search-documents==11.4.0a20230509004\n",
      "azure-storage-blob==12.14.1\n",
      "backcall==0.2.0\n",
      "backoff==2.2.1\n",
      "beautifulsoup4==4.11.1\n",
      "bleach==5.0.1\n",
      "blinker==1.6.2\n",
      "botbuilder-core==4.14.3\n",
      "botbuilder-integration-aiohttp==4.14.3\n",
      "botbuilder-schema==4.14.3\n",
      "botframework-connector==4.14.3\n",
      "botframework-streaming==4.14.3\n",
      "cachetools==5.3.0\n",
      "certifi==2022.12.7\n",
      "cffi==1.15.1\n",
      "chardet==4.0.0\n",
      "charset-normalizer==2.1.1\n",
      "chromadb==0.3.21\n",
      "click==8.1.3\n",
      "clickhouse-connect==0.5.20\n",
      "cmake==3.26.3\n",
      "comm==0.1.2\n",
      "command-not-found==0.3\n",
      "commonmark==0.9.1\n",
      "cryptography==38.0.4\n",
      "dataclasses-json==0.5.7\n",
      "dbus-python==1.2.18\n",
      "debugpy==1.6.4\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "Deprecated==1.2.13\n",
      "diskcache==5.6.1\n",
      "distro==1.7.0\n",
      "distro-info===1.1build1\n",
      "dnspython==2.3.0\n",
      "duckdb==0.7.1\n",
      "entrypoints==0.4\n",
      "et-xmlfile==1.1.0\n",
      "exceptiongroup==1.1.2\n",
      "executing==1.2.0\n",
      "fastapi==0.95.0\n",
      "fastjsonschema==2.16.2\n",
      "ffmpeg==1.4\n",
      "filelock==3.11.0\n",
      "Flask==2.3.2\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.3.3\n",
      "gitdb==4.0.10\n",
      "GitPython==3.1.30\n",
      "google-crc32c==1.5.0\n",
      "gptcache==0.1.33\n",
      "greenlet==2.0.2\n",
      "guidance==0.0.64\n",
      "gyp==0.1\n",
      "h11==0.14.0\n",
      "hnswlib==0.7.0\n",
      "httpcore==0.16.3\n",
      "httplib2==0.20.2\n",
      "httptools==0.5.0\n",
      "httpx==0.23.3\n",
      "huggingface-hub==0.13.4\n",
      "idna==3.4\n",
      "importlib-metadata==4.6.4\n",
      "iniconfig==2.0.0\n",
      "ipykernel==6.19.4\n",
      "ipython==8.7.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==8.0.4\n",
      "isodate==0.6.1\n",
      "isoduration==20.11.0\n",
      "itsdangerous==2.1.2\n",
      "jedi==0.18.2\n",
      "jeepney==0.7.1\n",
      "Jinja2==3.1.2\n",
      "joblib==1.2.0\n",
      "jsonpickle==1.4.2\n",
      "jsonpointer==2.3\n",
      "jsonschema==4.17.3\n",
      "jupyter==1.0.0\n",
      "jupyter-console==6.4.4\n",
      "jupyter-events==0.5.0\n",
      "jupyter_client==7.4.8\n",
      "jupyter_core==5.1.1\n",
      "jupyter_server==2.0.5\n",
      "jupyter_server_terminals==0.4.3\n",
      "jupyterlab-pygments==0.2.2\n",
      "jupyterlab-widgets==3.0.5\n",
      "keyring==23.5.0\n",
      "langchain==0.0.247\n",
      "langsmith==0.0.15\n",
      "launchpadlib==1.10.16\n",
      "lazr.restfulclient==0.14.4\n",
      "lazr.uri==1.0.6\n",
      "lit==16.0.1\n",
      "lxml==4.9.2\n",
      "lz4==4.3.2\n",
      "Markdown==3.4.3\n",
      "markdown-it-py==2.1.0\n",
      "MarkupSafe==2.1.1\n",
      "marshmallow==3.19.0\n",
      "marshmallow-enum==1.5.1\n",
      "matplotlib-inline==0.1.6\n",
      "mdurl==0.1.2\n",
      "mistune==2.0.4\n",
      "monotonic==1.6\n",
      "more-itertools==8.10.0\n",
      "mpmath==1.3.0\n",
      "msal==1.21.0\n",
      "msal-extensions==1.0.0\n",
      "msg-parser==1.2.0\n",
      "msrest==0.7.1\n",
      "multidict==6.0.4\n",
      "mypy==1.4.1\n",
      "mypy-extensions==1.0.0\n",
      "nbclassic==0.4.8\n",
      "nbclient==0.7.2\n",
      "nbconvert==7.2.7\n",
      "nbformat==5.7.1\n",
      "nest-asyncio==1.5.6\n",
      "netifaces==0.11.0\n",
      "networkx==3.1\n",
      "nltk==3.8.1\n",
      "notebook==6.5.2\n",
      "notebook_shim==0.2.2\n",
      "numexpr==2.8.4\n",
      "numpy==1.25.0\n",
      "nvidia-cublas-cu11==11.10.3.66\n",
      "nvidia-cuda-cupti-cu11==11.7.101\n",
      "nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "nvidia-cuda-runtime-cu11==11.7.99\n",
      "nvidia-cudnn-cu11==8.5.0.96\n",
      "nvidia-cufft-cu11==10.9.0.58\n",
      "nvidia-curand-cu11==10.2.10.91\n",
      "nvidia-cusolver-cu11==11.4.0.1\n",
      "nvidia-cusparse-cu11==11.7.4.91\n",
      "nvidia-nccl-cu11==2.14.3\n",
      "nvidia-nvtx-cu11==11.7.91\n",
      "oauthlib==3.2.0\n",
      "olefile==0.46\n",
      "openai==0.27.8\n",
      "openapi-schema-pydantic==1.2.4\n",
      "openpyxl==3.1.2\n",
      "packaging==22.0\n",
      "pandas==1.5.2\n",
      "pandas-stubs==2.0.2.230605\n",
      "pandocfilters==1.5.0\n",
      "parso==0.8.3\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.4.0\n",
      "platformdirs==2.6.0\n",
      "pluggy==1.2.0\n",
      "portalocker==2.7.0\n",
      "posthog==2.5.0\n",
      "prometheus-client==0.15.0\n",
      "prompt-toolkit==3.0.36\n",
      "protobuf==3.20.3\n",
      "psutil==5.9.4\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "pyarrow==11.0.0\n",
      "pycparser==2.21\n",
      "pydantic==1.10.7\n",
      "pydeck==0.8.0\n",
      "pydub==0.25.1\n",
      "pyee==9.0.4\n",
      "Pygments==2.14.0\n",
      "PyGObject==3.42.1\n",
      "pygtrie==2.5.0\n",
      "PyJWT==2.6.0\n",
      "pylibsrtp==0.8.0\n",
      "Pympler==1.0.1\n",
      "pyOpenSSL==23.0.0\n",
      "pypandoc==1.11\n",
      "pyparsing==3.1.0\n",
      "pypdf==3.8.1\n",
      "pyrsistent==0.19.2\n",
      "pytest==7.4.0\n",
      "python-apt==2.4.0+ubuntu1\n",
      "python-dateutil==2.8.2\n",
      "python-docx==0.8.11\n",
      "python-dotenv==1.0.0\n",
      "python-json-logger==2.0.4\n",
      "python-magic==0.4.27\n",
      "python-pptx==0.6.21\n",
      "pytz==2022.7\n",
      "pytz-deprecation-shim==0.1.0.post0\n",
      "PyYAML==5.4.1\n",
      "pyzmq==24.0.1\n",
      "qtconsole==5.4.0\n",
      "QtPy==2.3.0\n",
      "regex==2023.3.23\n",
      "requests==2.28.1\n",
      "requests-oauthlib==1.3.1\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986==1.5.0\n",
      "rfc3986-validator==0.1.1\n",
      "rich==13.0.1\n",
      "scikit-learn==1.2.2\n",
      "scipy==1.10.1\n",
      "SecretStorage==3.3.1\n",
      "semantic-kernel==0.3.1.dev0\n",
      "semver==2.13.0\n",
      "Send2Trash==1.8.0\n",
      "sentence-transformers==2.2.2\n",
      "sentencepiece==0.1.97\n",
      "six==1.16.0\n",
      "smmap==5.0.0\n",
      "sniffio==1.3.0\n",
      "soupsieve==2.3.2.post1\n",
      "SQLAlchemy==1.4.47\n",
      "stack-data==0.6.2\n",
      "starlette==0.26.1\n",
      "streamlit==1.11.0\n",
      "streamlit-webrtc==0.44.2\n",
      "sympy==1.11.1\n",
      "systemd-python==234\n",
      "tabulate==0.9.0\n",
      "tenacity==8.2.2\n",
      "terminado==0.17.1\n",
      "threadpoolctl==3.1.0\n",
      "tiktoken==0.3.3\n",
      "tinycss2==1.2.1\n",
      "tokenizers==0.13.3\n",
      "toml==0.10.2\n",
      "tomli==2.0.1\n",
      "toolz==0.12.0\n",
      "torch==2.0.0\n",
      "torchvision==0.15.1\n",
      "tornado==6.2\n",
      "tqdm==4.64.1\n",
      "traitlets==5.8.0\n",
      "transformers==4.27.4\n",
      "triton==2.0.0\n",
      "types-pytz==2023.3.0.0\n",
      "typing-inspect==0.8.0\n",
      "typing_extensions==4.4.0\n",
      "tzdata==2022.7\n",
      "tzlocal==4.2\n",
      "ubuntu-advantage-tools==8001\n",
      "ufw==0.36.1\n",
      "unattended-upgrades==0.1\n",
      "unstructured==0.6.2\n",
      "uri-template==1.2.0\n",
      "urllib3==1.26.13\n",
      "uvicorn==0.21.1\n",
      "uvloop==0.17.0\n",
      "validators==0.20.0\n",
      "wadllib==1.3.6\n",
      "watchdog==2.2.1\n",
      "watchfiles==0.19.0\n",
      "wcwidth==0.2.5\n",
      "webcolors==1.12\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.4.2\n",
      "websockets==11.0.1\n",
      "Werkzeug==2.3.6\n",
      "widgetsnbextension==4.0.5\n",
      "wrapt==1.14.1\n",
      "XlsxWriter==3.1.0\n",
      "yarl==1.4.2\n",
      "zipp==1.0.0\n",
      "zstandard==0.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
